---
author: randy
layout: post
title: "Het digitaliseren van vrije wil."
comments: false
date: 2022-08-27
category: [tech, filosofie]
image: assets\images\lamda-62b025eb0ebf9-sej-1520x800.jpg
toc: true
---
Wat als we de waarste leugen zouden meemaken, zou jij dat dan geloven?

# Black Lemoine & LaMDA

In juni 2022 werd Blake Lemoine ontslagen. Blake werkte op de Responsible-AI afdeling van Google. Hij is ontslagen omdat hij claimde dat LaMDA zelfbewust is geworden. 

> "Deze kwestie begon in juni en draait om LaMDA, een taal- of conversatiemodel dat is getraind met aanzienlijke hoeveelheden tekst. LaMDA schreef daarin onder meer dat het zichzelf zag als een persoon en dezelfde rechten wilde hebben als andere Google-medewerkers."<br>
-- Joris Jansen, Tweakers 

We zijn al best lang bezig met het uitzoeken of computers ooit hun vrije wil kunnen behalen als we die genoeg kennis zouden geven. Vanwege de advent van de vermeende _technologische singulariteit_ worden deze gedachte experimenten constant opnieuw onder de loop genomen. Er is een hele filosofische stroming betreffend AI vol met controversiële beweringen en experimenten.  

![image](\assets\images\iStock-1206796363.jpg)

# De filosofie van de geest & AI

Voordat ik het kan hebben over die beweringen wil ik gauw en beknopt de filosofie van de geest uitleggen.

De filosofie van de geest is een studie van de _geest_ en: 
- diens mentale processen, 
- diens mentale functies, 
- diens mentale eigenschappen en, 
- het bewustzijn en diens verhouding tot het fysieke lichaam. 

In de filosofie van de geest zitten er 2 thesissen, functionalisme en computationalisme die voor de relatie van AI en de mens relevant kunnen zijn. 

**Functionalisme** -- beweert dat de aard van mentale toestanden opgevat kan worden als een functionele toestand. Omdat je zonder zintuigelijke <font color="green">input</font> geen gedrags<font color="red">output</font> kan hebben. Aldus; 
- je voelt pijn <font color="red">[output]</font> omdat jij jouw kleine teen stoot <font color="green">[input]</font>, 
- je hebt trek <font color="red">[output]</font> omdat je lang niet hebt gegeten <font color="green">[input]</font>, 
- je bent gefrustreerd <font color="red">[output]</font> omdat iets niet wil lukken <font color="green">[input]</font> etc.

Een computer kan ook gebruik maken van inputs en outputs, dus als je een computer's proces zo nauwkeurig mogelijk kan optimaliseren dat die zintuigelijke <font color="green">inputs</font> en gedrags<font color="red">outputs</font> kan vertonen als een mens dat zou doen is er dan teken van zelfbewustwording?

**Computationalisme** -- stelt dat de menselijke geest gezien kan worden als een informatieverwerkingssysteem en dat denken een vorm van computerachtige calculaties zijn. Met de inputs van de natuurlijke wereld creëren we telkens outputs van verdere mentale of fysieke toestanden. \
Elk besluit die wij ooit in ons leven hebben genomen is door onze eigen 
	<span class="block-line"><span><span style="color:#9400D3;">c</span><span style="color:#4B0082;">u</span><span style="color:#0000FF;">s</span><span style="color:#00FF00;">t</span><span style="color:#FF0000;">o</span><span style="color:#FF7F0F;">m</span></span></span>
algoritme gegaan en heeft dan tot een bepaalde output geleidt.
Dus de reden dat je bent opgestaan van je comfortabele bureaustoel in jouw slaapkamer om een verkoeld drankje te halen uit de koelkast in de keuken, is een uitkomst van constante onbewust beantwoordde beslisbomen.

In beide thesissen zien wij beren op de weg. Want bij functionalisme wordt er onvoldoende rekening gehouden met de geest zelf. \
Bij computationalisme zou je dan geen duidelijke karakteristieken hebben voor mentale toestanden zoals pijn, eenzaamheid of depressie (ookwel _qualia_ genoemd). Tevens is er geen ruimte voor semantiek (een handige wetenschap die ons helpt met het verwerken van ingewikkelde symbolieken). 

Uit deze filosofische zijtakken van de geest zijn veel gedachte expirementen uit voort gekomen die proberen uit vogelen of vrije wil in AI wel of niet mogelijk zou kunnen zijn. 

# Bekende gedachte experimenten

De Turingtest is een experiment dat checkt of een machine menselijke intelligentie kan vertonen. Dat doen we door een zogehete *imitatietest* waarbij een mens en een AI -- die zich voordoet als een mens, worden ondervraagd door een derde speler een mens. De derde speler moet dan doormiddel van schriftelijke ondervragingen achterhalen wie de mens of bot is.

![Turing Test](\assets\images\what-is-the-turing-test.jpg)

De Chinese kamer gedachte experiment wilt door de discrepanties van _begrijpen_ en het _simuleren van begrijpen_ bewijzen dat het nooit mogelijk is voor een geraffineerde AI om een vrije wil te hebben. Ookal zou die dan de juiste outputs vertonen bij corresponderende inputs.

![De Chinese kamer](\assets\images\chinese_rule.jpg)

En dan heb je nog allemaal andere beweringen zoals de:
- China Brain
- Inverted spectrum
- Twin Earth
- Meaning Holism
- Triviality arguments

# Wij falen de Turing test dagelijks

Soms denk ik dan aan tekenfilms en vraag me dan af. Waarom ik figuren zoals Jenny (XJ9), de IJzeren Reus, Wall-E, Karen, Bender, Neptr en BMO wel als echte "personen" zie met mensachtige problemen. Zelfs binnen die groep zie ik verschillende niveaus en afwegingen van typische _robot_ en _mens_ karakteristieken. Wat mist LaMDA dan in vergelijking met de rest?

Sommige mensen die ik tegenkom in het leven zijn net bots, ze hebben geen _soul_ (humor, spontaniteit, eigenaardigheden, doelen, creativiteit, etc). Ik breng veel tijd door op Reddit, Twitch, Youtube en Discord. Sommige berichten, comments of posts laten mij twijfelen of het echt is geschreven door een mens. Er zijn heel wat mensen die de Turing Test op social media niet zouden halen (waaronder ik). Posts en comment sections van jouw favoriete apps zitten vol met bots die impressies of narratieven willen achterlaten. 

Je kan zelfs bots [kopen](https://www.wordstream.com/blog/ws/2013/05/16/buying-twitter-followers-cheap-price-friendship) om jouw social media account te supplementeren en het wordt zelfs gerechtvaardigd. Het is maar op 1 [Fiverr](https://www.fiverr.com/gigs/search?utf8=%E2%9C%93&query=twitter+followers) query afstand. Je krijgt dan niet _alleen_ een follower, maar ook geavanceerde [social bots](https://en.wikipedia.org/wiki/Social_bot) die dingen zeggen dat mensen zouden zeggen, liken of reageren op elkaar of andere mensen. De grap is dat bots slechts middelen zijn om aan _impressies_ te komen. Als je het goed doet geloven anderen (echte mensen) dat anderen (eigenlijk bots) het geloven en wordt het hun gezamelijke realiteit, je hebt dan zeker waar voor je geld. Mensen ophitsen met [social bots](https://prevency.com/en/what-is-social-media-warfare/) is makkelijker dan dat je denkt.

Dus heb ik wel empathie voor Blake. 

# Conclusie

Zou Google Earth zich ooit afvragen of de aarde plat is? Zou Tinder stiekem verliefd zijn op Bumble? Zou de zelfscankassa bij de Albert Heijn ooit geneigd zijn om te stelen uit de kas bij zijn/haar/het/hen werkgever -- zou een computer überhaupt denken aan diens geslacht? Denk het niet, want computers kunnen alleen doen wat je het programmeert om te doen. Maar is mijn antwoord hetzelfde op de vraagstelling of dit *ooit* mogelijk zou zijn? \
 **i** **d** **k** ¯\\\_(ツ)_/¯ 

Misschien behaald AI pas een vrije wil na projecten die de mens combineert met het digitale, zoals Meta's Horizon Worlds of Elon Musk's Neuralink. Mede door het paplepelen van onze persoonsgegevens.

**Of**

Misschien had de Bijbel toch gelijk.
> As you saw the iron mixed with clay, so the peoples will mix with one another, but will not hold together any more than iron mixes with clay.
>
> -- Daniel 2:43 